{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Import"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b36f3d266b50a18"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-08T09:56:33.527985800Z",
     "start_time": "2024-09-08T09:56:32.065310600Z"
    }
   },
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Start"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b76a3382989288dc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "h2o.init(ip = \"localhost\",\n",
    "port = 54321,\n",
    "start_h2o = True,\n",
    "max_mem_size=\"20G\",\n",
    "nthreads = -1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e824b44b3254ac3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Specify grid name"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8475f3949ff80e87"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "net_name='net_95_v1'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-08T09:57:11.474422400Z",
     "start_time": "2024-09-08T09:57:11.464227200Z"
    }
   },
   "id": "972ce5e64384f2ba"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Loading"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "108487cd3d2cf690"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "alt_x = np.load(f'./data/{net_name}/measured_data_x_alt.npy')\n",
    "alt_y = np.load(f'./data/{net_name}/data_y_alt.npy')\n",
    "data_x = alt_x\n",
    "data_y = alt_y\n",
    "\n",
    "split_train = int(0.8 * data_x.shape[0])\n",
    "train_x = data_x[:split_train, :]\n",
    "train_y = data_y[:split_train, :]\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(train_x, train_y, test_size=0.3, shuffle=True, random_state=42)\n",
    "\n",
    "num_input = 206\n",
    "num_output = 95\n",
    "\n",
    "in_columns = [str(i) for i in range(num_input)]\n",
    "out_columns = [str(i) for i in range(num_input, num_input + num_output)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-08T09:57:26.469321Z",
     "start_time": "2024-09-08T09:57:26.403389800Z"
    }
   },
   "id": "934eafc34b6e40f2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train and save models (one model per output node)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "803d961a37414390"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "time_limit=60"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7dc547212b48ae90"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(num_output):\n",
    "    if not os.path.exists(f'./h2o_models_{time_limit}_v1'):\n",
    "        os.makedirs(f'./h2o_models_{time_limit}_v1')\n",
    "\n",
    "for i in range(num_output):\n",
    "    print(f'Training for output #{i}')\n",
    "    train = np.hstack((train_x, train_y[:, i].reshape(-1, 1)))\n",
    "    columns_names = in_columns + [out_columns[i]]\n",
    "    train = h2o.H2OFrame(train, column_names=columns_names)\n",
    "    \n",
    "    x = in_columns\n",
    "    y = out_columns[i]\n",
    "    aml = H2OAutoML(max_models=2, seed=1, max_runtime_secs_per_model=time_limit)\n",
    "    aml.train(x=x, y=y, training_frame=train)\n",
    "    \n",
    "    model_path = f'./h2o_models_{time_limit}_v1/model_{i}'\n",
    "    aml = h2o.save_model(model=aml.leader, path=model_path, force=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9385661ab0959c21"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load models (when necessary)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9164c52f718e460e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(num_output):\n",
    "    model_path = f'./h2o_models_{time_limit}_v1/model_{i}/'\n",
    "    files = os.listdir(model_path)\n",
    "    model_filename = [f for f in files if os.path.isfile(os.path.join(model_path, f))][0]\n",
    "    \n",
    "    aml = h2o.load_model(f'{model_path}/{model_filename}')\n",
    "    models.append(aml)\n",
    "    print(f'Model {i} loaded')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a951c9c5623eae8f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Collect metric for validation data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8cc366cb27c06d7f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from net95.scenarios2 import get_data_by_scenario_and_case\n",
    "\n",
    "std_results = []\n",
    "for scenario in range(1, 2):\n",
    "    for case in range(1, 2):\n",
    "        print(f'SCENARIO {scenario}, CASE {case} VALIDATION')\n",
    "        s1_c1_data = get_data_by_scenario_and_case(scenario, case, net_name='net95v1')\n",
    "        x = s1_c1_data[0]\n",
    "        x_hat = s1_c1_data[1]\n",
    "        y_all = s1_c1_data[2]\n",
    "        y_hat_all = s1_c1_data[3]\n",
    "        \n",
    "        estim = []\n",
    "        for i in range(num_output):\n",
    "            columns_names = in_columns + [out_columns[i]]\n",
    "            x = in_columns\n",
    "            y = out_columns[i]\n",
    "            \n",
    "            aml = models[i]\n",
    "            test_x = x_hat\n",
    "            test_y = np.asarray(y_all[0][i]).reshape(-1, 1)\n",
    "            test = h2o.H2OFrame(np.hstack((test_x, test_y)), column_names=columns_names)\n",
    "            \n",
    "            try:\n",
    "                preds = aml.leader.predict(test)\n",
    "            except:\n",
    "                preds = aml.predict(test)\n",
    "            estim.append(preds['predict'].as_data_frame().iloc[0][0])\n",
    "            \n",
    "        pred = np.asarray(estim)\n",
    "        #report_preds_on_validation_files(pred, 9, 'h2o', scenario, case=case)\n",
    "        if case == 1:\n",
    "            std_results.append(f'std: {np.sqrt(np.mean(np.square(y_all - pred)))}')\n",
    "print(std_results)\n",
    "print(preds)\n",
    "print(y_all)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49ace0b57b33d5e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate local explanations with shap\n",
    "In this case local explanations are generated for the output index #30 and are applied to explain the models' output when the input correspond to scenario 1 case 1."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebafb1732e0042a9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import shap\n",
    "import pandas as pd\n",
    "from net95.scenarios2 import get_data_by_scenario_and_case\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "scenario=1\n",
    "case=1\n",
    "node_index = 30\n",
    "predictor = models[node_index] # I want to explain state estimation for node at index 30\n",
    "columns_names = in_columns + [out_columns[node_index]]\n",
    "\n",
    "def wrapped_model(x):\n",
    "    x = h2o.H2OFrame(x)\n",
    "    x.col_names = columns_names[:-1]\n",
    "    preds = predictor.predict(x).as_data_frame().to_numpy()[:, 0]\n",
    "    return preds\n",
    "\n",
    "s1_c1_data = get_data_by_scenario_and_case(scenario, case, net_name='net95v1')\n",
    "x = s1_c1_data[0]\n",
    "x_hat = s1_c1_data[1]\n",
    "y_all = s1_c1_data[2]\n",
    "y_hat_all = s1_c1_data[3]\n",
    "to_be_explained = x\n",
    "\n",
    "random_indices = np.random.choice(test_x.shape[0], size=100, replace=False)\n",
    "explainer = shap.KernelExplainer(wrapped_model, train_x[random_indices])\n",
    "shap_values = explainer.shap_values(to_be_explained)\n",
    "relevance = abs(shap_values.ravel())\n",
    "\n",
    "x_positions = np.arange(len(relevance))\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.bar(x_positions, relevance, color='green')\n",
    "plt.xlabel('Model input index')\n",
    "plt.ylabel('Contributions')\n",
    "plt.title(f'SHAP Values for H2O - output index {node_index}')\n",
    "#plt.xticks(x_positions, ['A', 'B', 'C', 'D', 'E'])\n",
    "print(sorted([(i, j) for i,j in enumerate(relevance)], key=lambda t: -t[1])[:10])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "labels = ['p_mw', 'q_mvar', 'vm_pu', 'p_mw_lines', 'q__mvar_lines']\n",
    "aggregate_data = [sum(relevance[:94])/94., sum(relevance[94:94+94])/94., sum(relevance[94+94:94+94+4])/4., sum(relevance[94+94+4:94+94+4+7])/7., sum(relevance[94+94+4+7:])/7.]\n",
    "ax.pie(aggregate_data, labels=labels, autopct='%1.1f%%')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "labels = ['vm_pu', 'other']\n",
    "aggregate_data = [sum(relevance[94+94:94+94+4])/4., sum(relevance[:94])/94. + sum(relevance[94:94+94])/94. + sum(relevance[94+94+4:94+94+4+7])/7. + sum(relevance[94+94+4+7:])/7.]\n",
    "ax.pie(aggregate_data, labels=labels, autopct='%1.1f%%')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "labels = ['p_mw', 'q_mvar', 'p_mw_lines', 'q__mvar_lines']\n",
    "aggregate_data = [sum(relevance[:94])/94., sum(relevance[94:94+94])/94., sum(relevance[94+94+4:94+94+4+7])/7., sum(relevance[94+94+4+7:])/7.]\n",
    "ax.pie(aggregate_data, labels=labels, autopct='%1.1f%%')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "norm_relevance = ((relevance-abs(relevance)) / (max(relevance) - min(relevance)))\n",
    "\n",
    "print(relevance)\n",
    "plt.imshow(norm_relevance.reshape((53, 1)))\n",
    "plt.colorbar()\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88cb9cee2a01e4c2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
