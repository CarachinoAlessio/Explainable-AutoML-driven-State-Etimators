{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:06:31.096732700Z",
     "start_time": "2024-02-26T12:06:30.402048700Z"
    }
   },
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 17.0.10+11-LTS-240, mixed mode, sharing)\n",
      "  Starting server from C:\\Users\\aless\\Documents\\GitHub\\ML-techniques-for-State-Estimation\\venv\\Lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\aless\\AppData\\Local\\Temp\\tmph7a5w2_b\n",
      "  JVM stdout: C:\\Users\\aless\\AppData\\Local\\Temp\\tmph7a5w2_b\\h2o_aless_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\aless\\AppData\\Local\\Temp\\tmph7a5w2_b\\h2o_aless_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/plain": "--------------------------  -----------------------------\nH2O_cluster_uptime:         01 secs\nH2O_cluster_timezone:       Europe/Rome\nH2O_data_parsing_timezone:  UTC\nH2O_cluster_version:        3.44.0.3\nH2O_cluster_version_age:    2 months and 5 days\nH2O_cluster_name:           H2O_from_python_aless_eku3tu\nH2O_cluster_total_nodes:    1\nH2O_cluster_free_memory:    16 Gb\nH2O_cluster_total_cores:    20\nH2O_cluster_allowed_cores:  20\nH2O_cluster_status:         locked, healthy\nH2O_connection_url:         http://127.0.0.1:54321\nH2O_connection_proxy:       {\"http\": null, \"https\": null}\nH2O_internal_security:      False\nPython_version:             3.10.11 final\n--------------------------  -----------------------------",
      "text/html": "\n<style>\n\n#h2o-table-1.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-1 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-1 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-1 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-1 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-1 .h2o-table th,\n#h2o-table-1 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-1 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-1\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption></caption>\n    <thead></thead>\n    <tbody><tr><td>H2O_cluster_uptime:</td>\n<td>01 secs</td></tr>\n<tr><td>H2O_cluster_timezone:</td>\n<td>Europe/Rome</td></tr>\n<tr><td>H2O_data_parsing_timezone:</td>\n<td>UTC</td></tr>\n<tr><td>H2O_cluster_version:</td>\n<td>3.44.0.3</td></tr>\n<tr><td>H2O_cluster_version_age:</td>\n<td>2 months and 5 days</td></tr>\n<tr><td>H2O_cluster_name:</td>\n<td>H2O_from_python_aless_eku3tu</td></tr>\n<tr><td>H2O_cluster_total_nodes:</td>\n<td>1</td></tr>\n<tr><td>H2O_cluster_free_memory:</td>\n<td>16 Gb</td></tr>\n<tr><td>H2O_cluster_total_cores:</td>\n<td>20</td></tr>\n<tr><td>H2O_cluster_allowed_cores:</td>\n<td>20</td></tr>\n<tr><td>H2O_cluster_status:</td>\n<td>locked, healthy</td></tr>\n<tr><td>H2O_connection_url:</td>\n<td>http://127.0.0.1:54321</td></tr>\n<tr><td>H2O_connection_proxy:</td>\n<td>{\"http\": null, \"https\": null}</td></tr>\n<tr><td>H2O_internal_security:</td>\n<td>False</td></tr>\n<tr><td>Python_version:</td>\n<td>3.10.11 final</td></tr></tbody>\n  </table>\n</div>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init(ip = \"localhost\",\n",
    "port = 54321,\n",
    "start_h2o = True,\n",
    "max_mem_size=\"16G\",\n",
    "nthreads = -1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:06:55.037786800Z",
     "start_time": "2024-02-26T12:06:31.097232900Z"
    }
   },
   "id": "947fb64133f11a5e"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "alt_x = np.load('../nets/net_18_data/measured_data_x_alt.npy')\n",
    "alt_y = np.load('../nets/net_18_data/data_y_alt.npy')\n",
    "data_x = alt_x\n",
    "data_y = alt_y\n",
    "\n",
    "split_train = int(0.8 * data_x.shape[0])\n",
    "train_x = data_x[:split_train, :]\n",
    "train_y = data_y[:split_train, :]\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(train_x, train_y, test_size=0.3, shuffle=True, random_state=42)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:07:21.018345600Z",
     "start_time": "2024-02-26T12:07:20.982346500Z"
    }
   },
   "id": "8003b9514dd6505b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "num_input = 53\n",
    "num_output = 18\n",
    "\n",
    "in_columns = [str(i) for i in range(num_input)]\n",
    "out_columns = [str(i) for i in range(num_input, num_input + num_output)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:07:21.450297Z",
     "start_time": "2024-02-26T12:07:21.430297500Z"
    }
   },
   "id": "815b96bd2fa485ea"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for output #0\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "16:29:36.679: AutoML: XGBoost is not available; skipping it.\n",
      "███████████████████████████████████████████████████████████████| (done) 100%\n",
      "Training for output #1\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "16:30:15.225: AutoML: XGBoost is not available; skipping it.\n",
      "███████████████████████████████████████████████████████████████| (done) 100%\n",
      "Training for output #2\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "16:30:47.523: AutoML: XGBoost is not available; skipping it.\n",
      "███████████████████████████████████████████████████████████████| (done) 100%\n",
      "Training for output #3\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "16:31:18.29: AutoML: XGBoost is not available; skipping it.\n",
      "███████████████████████████████████████████████████████████████| (done) 100%\n",
      "Training for output #4\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "16:31:48.711: AutoML: XGBoost is not available; skipping it.\n",
      "███████████████████████████████████████████████████████████████| (done) 100%\n",
      "Training for output #5\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "16:32:20.832: AutoML: XGBoost is not available; skipping it.\n",
      "███████████████████████████████████████████████████████████████| (done) 100%\n",
      "Training for output #6\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "16:32:52.780: AutoML: XGBoost is not available; skipping it.\n",
      "███████████████████████████████████████████████████████████████| (done) 100%\n",
      "Training for output #7\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "16:33:24.993: AutoML: XGBoost is not available; skipping it.\n",
      "███████████████████████████████████████████████████████████████| (done) 100%\n",
      "Training for output #8\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "16:33:56.967: AutoML: XGBoost is not available; skipping it.\n",
      "███████████████████████████████████████████████████████████████| (done) 100%\n",
      "Training for output #9\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "16:34:30.396: AutoML: XGBoost is not available; skipping it.\n",
      "███████████████████████████████████████████████████████████████| (done) 100%\n",
      "Training for output #10\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "16:35:02.653: AutoML: XGBoost is not available; skipping it.\n",
      "███████████████████████████████████████████████████████████████| (done) 100%\n",
      "Training for output #11\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "16:35:36.290: AutoML: XGBoost is not available; skipping it.\n",
      "███████████████████████████████████████████████████████████████| (done) 100%\n",
      "Training for output #12\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "16:36:09.662: AutoML: XGBoost is not available; skipping it.\n",
      "███████████████████████████████████████████████████████████████| (done) 100%\n",
      "Training for output #13\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "16:36:44.652: AutoML: XGBoost is not available; skipping it.\n",
      "███████████████████████████████████████████████████████████████| (done) 100%\n",
      "Training for output #14\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "16:37:23.370: AutoML: XGBoost is not available; skipping it.\n",
      "███████████████████████████████████████████████████████████████| (done) 100%\n",
      "Training for output #15\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "16:38:11.463: AutoML: XGBoost is not available; skipping it.\n",
      "███████████████████████████████████████████████████████████████| (done) 100%\n",
      "Training for output #16\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "16:38:41.927: AutoML: XGBoost is not available; skipping it.\n",
      "███████████████████████████████████████████████████████████████| (done) 100%\n",
      "Training for output #17\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "16:39:12.446: AutoML: XGBoost is not available; skipping it.\n",
      "███████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "train_models = True\n",
    "if train_models:\n",
    "    for i in range(num_output):\n",
    "        print(f'Training for output #{i}')\n",
    "        train = np.hstack((train_x, train_y[:, i].reshape(-1, 1)))\n",
    "        columns_names = in_columns + [out_columns[i]]\n",
    "        train = h2o.H2OFrame(train, column_names=columns_names)\n",
    "        \n",
    "        x = in_columns\n",
    "        y = out_columns[i]\n",
    "        aml = H2OAutoML(max_models=3, seed=1, max_runtime_secs_per_model=180)\n",
    "        aml.train(x=x, y=y, training_frame=train, )\n",
    "        \n",
    "        model_path = f'./h2o_models/model_{i}'\n",
    "        aml = h2o.save_model(model=aml.leader, path=model_path, force=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T15:39:42.151311400Z",
     "start_time": "2024-02-20T15:29:35.401438500Z"
    }
   },
   "id": "d1e1333565ba3f6b"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "glm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 19\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m     18\u001B[0m     preds \u001B[38;5;241m=\u001B[39m aml\u001B[38;5;241m.\u001B[39mpredict(test)\n\u001B[1;32m---> 19\u001B[0m \u001B[43mtest_predictions\u001B[49m\u001B[38;5;241m.\u001B[39mappend(preds[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpredict\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     20\u001B[0m perf \u001B[38;5;241m=\u001B[39m aml\u001B[38;5;241m.\u001B[39mmodel_performance(test)\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMSE for model \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mperf\u001B[38;5;241m.\u001B[39m_metric_json[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMSE\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[25], line 19\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m     18\u001B[0m     preds \u001B[38;5;241m=\u001B[39m aml\u001B[38;5;241m.\u001B[39mpredict(test)\n\u001B[1;32m---> 19\u001B[0m \u001B[43mtest_predictions\u001B[49m\u001B[38;5;241m.\u001B[39mappend(preds[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpredict\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     20\u001B[0m perf \u001B[38;5;241m=\u001B[39m aml\u001B[38;5;241m.\u001B[39mmodel_performance(test)\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMSE for model \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mperf\u001B[38;5;241m.\u001B[39m_metric_json[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMSE\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:929\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:920\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:317\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\PyCharm Professional\\plugins\\python\\helpers\\pydev\\pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\PyCharm Professional\\plugins\\python\\helpers\\pydev\\pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1175\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "test_predictions = []\n",
    "for i in range(num_output):\n",
    "    columns_names = in_columns + [out_columns[i]]\n",
    "    x = in_columns\n",
    "    y = out_columns[i]\n",
    "    \n",
    "    test = np.hstack((test_x, test_y[:, i].reshape(-1, 1)))\n",
    "    test = h2o.H2OFrame(test, column_names=columns_names)\n",
    "    \n",
    "    model_path = f'./h2o_models/model_{i}/'\n",
    "    files = os.listdir(model_path)\n",
    "    model_filename = [f for f in files if os.path.isfile(os.path.join(model_path, f))][0]\n",
    "    \n",
    "    aml = h2o.load_model(f'{model_path}/{model_filename}')\n",
    "    try:\n",
    "        preds = aml.leader.predict(test)\n",
    "    except:\n",
    "        preds = aml.predict(test)\n",
    "    test_predictions.append(preds['predict'])\n",
    "    perf = aml.model_performance(test)\n",
    "    print(f\"MSE for model {i}: {perf._metric_json['MSE']}\")\n",
    "    print('---------------------------------')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T12:02:30.621912500Z",
     "start_time": "2024-02-21T12:02:14.566671300Z"
    }
   },
   "id": "bc57d235ae0144b6"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0 loaded\n",
      "Model 1 loaded\n",
      "Model 2 loaded\n",
      "Model 3 loaded\n",
      "Model 4 loaded\n",
      "Model 5 loaded\n",
      "Model 6 loaded\n",
      "Model 7 loaded\n",
      "Model 8 loaded\n",
      "Model 9 loaded\n",
      "Model 10 loaded\n",
      "Model 11 loaded\n",
      "Model 12 loaded\n",
      "Model 13 loaded\n",
      "Model 14 loaded\n",
      "Model 15 loaded\n",
      "Model 16 loaded\n",
      "Model 17 loaded\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for i in range(num_output):\n",
    "    model_path = f'./h2o_models/model_{i}/'\n",
    "    files = os.listdir(model_path)\n",
    "    model_filename = [f for f in files if os.path.isfile(os.path.join(model_path, f))][0]\n",
    "    \n",
    "    aml = h2o.load_model(f'{model_path}/{model_filename}')\n",
    "    models.append(aml)\n",
    "    print(f'Model {i} loaded')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:07:28.976798600Z",
     "start_time": "2024-02-26T12:07:28.360298300Z"
    }
   },
   "id": "9685735c5423a2d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from net18.scenarios2 import get_data_by_scenario_and_case, report_preds_on_validation_files\n",
    "\n",
    "std_results = []\n",
    "for scenario in range(1, 6):\n",
    "    for case in range(1, 4):\n",
    "        print(f'SCENARIO {scenario}, CASE {case} VALIDATION')\n",
    "        s1_c1_data = get_data_by_scenario_and_case(scenario, case)\n",
    "        x = s1_c1_data[0]\n",
    "        x_hat = s1_c1_data[1]\n",
    "        y_all = s1_c1_data[2]\n",
    "        y_hat_all = s1_c1_data[3]\n",
    "        \n",
    "        estim = []\n",
    "        for i in range(num_output):\n",
    "            columns_names = in_columns + [out_columns[i]]\n",
    "            x = in_columns\n",
    "            y = out_columns[i]\n",
    "            \n",
    "            aml = models[i]\n",
    "            test_x = x_hat\n",
    "            test_y = np.asarray(y_all[0][i]).reshape(-1, 1)\n",
    "            test = h2o.H2OFrame(np.hstack((test_x, test_y)), column_names=columns_names)\n",
    "            \n",
    "            try:\n",
    "                preds = aml.leader.predict(test)\n",
    "            except:\n",
    "                preds = aml.predict(test)\n",
    "            estim.append(preds['predict'].as_data_frame().iloc[0][0])\n",
    "            \n",
    "        pred = np.asarray(estim)\n",
    "        report_preds_on_validation_files(pred, 9, 'h2o', scenario, case=case)\n",
    "        if case == 1:\n",
    "            std_results.append(f'std: {np.sqrt(np.mean(np.square(y_all - pred)))}')\n",
    "print(std_results)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c91c44008cd32294"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dcd972f5b14a4024"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std: 0.008439554785042516\n"
     ]
    }
   ],
   "source": [
    "pred = np.asarray(estim)\n",
    "print(f'std: {np.sqrt(np.mean(np.square(y_all - pred)))}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T14:05:34.810183300Z",
     "start_time": "2024-02-23T14:05:34.805170800Z"
    }
   },
   "id": "bf8dba40a9631851"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# std res\n",
    "['std: 0.008439554785042516', 'std: 0.006391693699890966', 'std: 0.004519067368293418', 'std: 0.0038331904856998235', 'std: 0.0013468433143673563']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "621a0939a1bd162f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
