{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-26T12:16:37.621325Z",
     "start_time": "2024-02-26T12:16:36.919214Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import autosklearn.regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8003b9514dd6505b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T18:27:53.851791Z",
     "start_time": "2024-02-25T18:27:53.832536Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "alt_x = np.load('../nets/net_18_data/measured_data_x_alt.npy')\n",
    "alt_y = np.load('../nets/net_18_data/data_y_alt.npy')\n",
    "data_x = alt_x\n",
    "data_y = alt_y\n",
    "\n",
    "split_train = int(0.8 * data_x.shape[0])\n",
    "train_x = data_x[:split_train, :]\n",
    "train_y = data_y[:split_train, :]\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(train_x, train_y, test_size=0.3, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "815b96bd2fa485ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T18:28:04.957392Z",
     "start_time": "2024-02-25T18:28:04.953994Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "num_input = 53\n",
    "num_output = 18\n",
    "\n",
    "in_columns = [str(i) for i in range(num_input)]\n",
    "out_columns = [str(i) for i in range(num_input, num_input + num_output)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1e1333565ba3f6b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-25T18:41:30.257998Z"
    },
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for output #0\n",
      "[WARNING] [2024-02-26 11:32:43,560:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2024-02-26 11:32:44,948:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2024-02-26 11:34:06,003:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2024-02-26 11:35:27,110:Client-EnsembleBuilder] No runs were available to build an ensemble from\n"
     ]
    }
   ],
   "source": [
    "train_models = True\n",
    "if train_models:\n",
    "    for i in range(num_output):\n",
    "        print(f'Training for output #{i}')\n",
    "        train = np.hstack((train_x, train_y[:, i].reshape(-1, 1)))\n",
    "        columns_names = in_columns + [out_columns[i]]\n",
    "        train = pd.DataFrame(train, columns=columns_names)\n",
    "        \n",
    "        x = in_columns\n",
    "        y = out_columns[i]\n",
    "        label = y\n",
    "        \n",
    "        train_x = train_x\n",
    "        train_yi = train_y[:, i].reshape(-1, 1)\n",
    "        \n",
    "        model_path = f'./autosklearn_models/model_{i}'\n",
    "        automl = autosklearn.regression.AutoSklearnRegressor(\n",
    "            time_left_for_this_task=540,\n",
    "        )\n",
    "        automl.fit(train_x, train_yi)\n",
    "        \n",
    "        with open(f'{model_path}.pkl', 'wb') as f:\n",
    "            pickle.dump(automl, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc57d235ae0144b6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "test_predictions = []\n",
    "for i in range(num_output):\n",
    "    columns_names = in_columns + [out_columns[i]]\n",
    "    x = in_columns\n",
    "    y = out_columns[i]\n",
    "    \n",
    "    test = np.hstack((test_x, test_y[:, i].reshape(-1, 1)))\n",
    "    test = h2o.H2OFrame(test, column_names=columns_names)\n",
    "    \n",
    "    model_path = f'./autogluon_models/model_{i}/'\n",
    "    files = os.listdir(model_path)\n",
    "    model_filename = [f for f in files if os.path.isfile(os.path.join(model_path, f))][0]\n",
    "    \n",
    "    aml = h2o.load_model(f'{model_path}/{model_filename}')\n",
    "    try:\n",
    "        preds = aml.leader.predict(test)\n",
    "    except:\n",
    "        preds = aml.predict(test)\n",
    "    test_predictions.append(preds['predict'])\n",
    "    perf = aml.model_performance(test)\n",
    "    print(f\"MSE for model {i}: {perf._metric_json['MSE']}\")\n",
    "    print('---------------------------------')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9685735c5423a2d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T16:05:19.379751500Z",
     "start_time": "2024-02-23T16:05:19.343186800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0 loaded\n",
      "Model 1 loaded\n",
      "Model 2 loaded\n",
      "Model 3 loaded\n",
      "Model 4 loaded\n",
      "Model 5 loaded\n",
      "Model 6 loaded\n",
      "Model 7 loaded\n",
      "Model 8 loaded\n",
      "Model 9 loaded\n",
      "Model 10 loaded\n",
      "Model 11 loaded\n",
      "Model 12 loaded\n",
      "Model 13 loaded\n",
      "Model 14 loaded\n",
      "Model 15 loaded\n",
      "Model 16 loaded\n",
      "Model 17 loaded\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for i in range(num_output):\n",
    "    model_path = f'./autosklearn_models/model_{i}'\n",
    "    label = out_columns[i]\n",
    "\n",
    "    with open(f'{model_path}.pkl', 'rb') as f:\n",
    "        automl = pickle.load(f)\n",
    "        \n",
    "    models.append(automl)\n",
    "    print(f'Model {i} loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c91c44008cd32294",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T16:09:14.938395Z",
     "start_time": "2024-02-23T16:08:39.688458300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCENARIO 1, CASE 1 VALIDATION\n",
      "SCENARIO 1, CASE 2 VALIDATION\n",
      "SCENARIO 1, CASE 3 VALIDATION\n",
      "SCENARIO 2, CASE 1 VALIDATION\n",
      "SCENARIO 2, CASE 2 VALIDATION\n",
      "SCENARIO 2, CASE 3 VALIDATION\n",
      "SCENARIO 3, CASE 1 VALIDATION\n",
      "SCENARIO 3, CASE 2 VALIDATION\n",
      "SCENARIO 3, CASE 3 VALIDATION\n",
      "SCENARIO 4, CASE 1 VALIDATION\n",
      "SCENARIO 4, CASE 2 VALIDATION\n",
      "SCENARIO 4, CASE 3 VALIDATION\n",
      "SCENARIO 5, CASE 1 VALIDATION\n",
      "SCENARIO 5, CASE 2 VALIDATION\n",
      "SCENARIO 5, CASE 3 VALIDATION\n",
      "['std: 0.00808208839787624', 'std: 0.005858026139478702', 'std: 0.004225356951975962', 'std: 0.003758065993384607', 'std: 0.001328562050920048']\n"
     ]
    }
   ],
   "source": [
    "from net18.scenarios2 import get_data_by_scenario_and_case, report_preds_on_validation_files\n",
    "\n",
    "std_results = []\n",
    "for scenario in range(1, 6):\n",
    "    for case in range(1, 4):\n",
    "        print(f'SCENARIO {scenario}, CASE {case} VALIDATION')\n",
    "        s1_c1_data = get_data_by_scenario_and_case(scenario, case)\n",
    "        x = s1_c1_data[0]\n",
    "        x_hat = s1_c1_data[1]\n",
    "        y_all = s1_c1_data[2]\n",
    "        y_hat_all = s1_c1_data[3]\n",
    "        \n",
    "        estim = []\n",
    "        for i in range(num_output):\n",
    "            columns_names = in_columns + [\n",
    "                out_columns[i]]\n",
    "            x = in_columns\n",
    "            y = out_columns[i]\n",
    "            \n",
    "            predictor = models[i]\n",
    "            test_x = x_hat\n",
    "            test_y = np.asarray(y_all[0][i]).reshape(-1, 1)\n",
    "            test = pd.DataFrame(np.hstack((test_x, test_y)), columns=columns_names)\n",
    "            \n",
    "            \n",
    "            preds = predictor.predict(test_x)\n",
    "            \n",
    "            estim.append(preds[0])\n",
    "            \n",
    "        pred = np.asarray(estim)\n",
    "        report_preds_on_validation_files(pred, 10, 'autosklearn', scenario, case=case)\n",
    "        if case == 1:\n",
    "            std_results.append(f'std: {np.sqrt(np.mean(np.square(y_all - pred)))}')\n",
    "print(std_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf8dba40a9631851",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T14:05:34.810183300Z",
     "start_time": "2024-02-23T14:05:34.805170800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'estim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43mestim\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39msquare(y_all\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mpred)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'estim' is not defined"
     ]
    }
   ],
   "source": [
    "pred = np.asarray(estim)\n",
    "print(f'std: {np.sqrt(np.mean(np.square(y_all - pred)))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621a0939a1bd162f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
