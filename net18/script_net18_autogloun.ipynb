{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-26T11:51:23.618269Z",
     "start_time": "2024-02-26T11:51:22.701269400Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import time\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "alt_x = np.load('../nets/net_18_data/measured_data_x_alt.npy')\n",
    "alt_y = np.load('../nets/net_18_data/data_y_alt.npy')\n",
    "data_x = alt_x\n",
    "data_y = alt_y\n",
    "\n",
    "split_train = int(0.8 * data_x.shape[0])\n",
    "train_x = data_x[:split_train, :]\n",
    "train_y = data_y[:split_train, :]\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(train_x, train_y, test_size=0.3, shuffle=True, random_state=42)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T11:51:23.629268500Z",
     "start_time": "2024-02-26T11:51:23.607768800Z"
    }
   },
   "id": "8003b9514dd6505b"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "num_input = 53\n",
    "num_output = 18\n",
    "\n",
    "in_columns = [str(i) for i in range(num_input)]\n",
    "out_columns = [str(i) for i in range(num_input, num_input + num_output)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T11:51:23.647769600Z",
     "start_time": "2024-02-26T11:51:23.630269800Z"
    }
   },
   "id": "815b96bd2fa485ea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_models = True\n",
    "if train_models:\n",
    "    for i in range(num_output):\n",
    "        print(f'Training for output #{i}')\n",
    "        train = np.hstack((train_x, train_y[:, i].reshape(-1, 1)))\n",
    "        columns_names = in_columns + [out_columns[i]]\n",
    "        train = pd.DataFrame(train, columns=columns_names)\n",
    "        \n",
    "        x = in_columns\n",
    "        y = out_columns[i]\n",
    "        label = y\n",
    "        model_path = f'./autogluon_models/model_{i}'\n",
    "        \n",
    "        predictor = TabularPredictor(label=label, problem_type='regression', eval_metric='mean_squared_error', path=model_path).fit(train, time_limit=540)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1e1333565ba3f6b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "test_predictions = []\n",
    "for i in range(num_output):\n",
    "    columns_names = in_columns + [out_columns[i]]\n",
    "    x = in_columns\n",
    "    y = out_columns[i]\n",
    "    \n",
    "    test = np.hstack((test_x, test_y[:, i].reshape(-1, 1)))\n",
    "    test = h2o.H2OFrame(test, column_names=columns_names)\n",
    "    \n",
    "    model_path = f'./autogluon_models/model_{i}/'\n",
    "    files = os.listdir(model_path)\n",
    "    model_filename = [f for f in files if os.path.isfile(os.path.join(model_path, f))][0]\n",
    "    \n",
    "    aml = h2o.load_model(f'{model_path}/{model_filename}')\n",
    "    try:\n",
    "        preds = aml.leader.predict(test)\n",
    "    except:\n",
    "        preds = aml.predict(test)\n",
    "    test_predictions.append(preds['predict'])\n",
    "    perf = aml.model_performance(test)\n",
    "    print(f\"MSE for model {i}: {perf._metric_json['MSE']}\")\n",
    "    print('---------------------------------')\n",
    "'''\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc57d235ae0144b6"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./autogluon_models/model_0/\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./autogluon_models/model_1/\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./autogluon_models/model_2/\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./autogluon_models/model_3/\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./autogluon_models/model_4/\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./autogluon_models/model_5/\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./autogluon_models/model_6/\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./autogluon_models/model_7/\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./autogluon_models/model_8/\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./autogluon_models/model_9/\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./autogluon_models/model_10/\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./autogluon_models/model_11/\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./autogluon_models/model_12/\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./autogluon_models/model_13/\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./autogluon_models/model_14/\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./autogluon_models/model_15/\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./autogluon_models/model_16/\"\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./autogluon_models/model_17/\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0 loaded\n",
      "Model 1 loaded\n",
      "Model 2 loaded\n",
      "Model 3 loaded\n",
      "Model 4 loaded\n",
      "Model 5 loaded\n",
      "Model 6 loaded\n",
      "Model 7 loaded\n",
      "Model 8 loaded\n",
      "Model 9 loaded\n",
      "Model 10 loaded\n",
      "Model 11 loaded\n",
      "Model 12 loaded\n",
      "Model 13 loaded\n",
      "Model 14 loaded\n",
      "Model 15 loaded\n",
      "Model 16 loaded\n",
      "Model 17 loaded\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for i in range(num_output):\n",
    "    model_path = f'./autogluon_models/model_{i}/'\n",
    "    files = os.listdir(model_path)\n",
    "    #model_filename = [f for f in files if os.path.isfile(os.path.join(model_path, f))][0]\n",
    "    label = out_columns[i]\n",
    "    \n",
    "    predictor = TabularPredictor(label=label, problem_type='regression', eval_metric='mean_squared_error', path=model_path).load(f'{model_path}')\n",
    "    models.append(predictor)\n",
    "    print(f'Model {i} loaded')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T11:51:26.886092600Z",
     "start_time": "2024-02-26T11:51:26.851672Z"
    }
   },
   "id": "9685735c5423a2d7"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCENARIO 1, CASE 1 VALIDATION\n",
      "SCENARIO 1, CASE 2 VALIDATION\n",
      "SCENARIO 1, CASE 3 VALIDATION\n",
      "SCENARIO 2, CASE 1 VALIDATION\n",
      "SCENARIO 2, CASE 2 VALIDATION\n",
      "SCENARIO 2, CASE 3 VALIDATION\n",
      "SCENARIO 3, CASE 1 VALIDATION\n",
      "SCENARIO 3, CASE 2 VALIDATION\n",
      "SCENARIO 3, CASE 3 VALIDATION\n",
      "SCENARIO 4, CASE 1 VALIDATION\n",
      "SCENARIO 4, CASE 2 VALIDATION\n",
      "SCENARIO 4, CASE 3 VALIDATION\n",
      "SCENARIO 5, CASE 1 VALIDATION\n",
      "SCENARIO 5, CASE 2 VALIDATION\n",
      "SCENARIO 5, CASE 3 VALIDATION\n",
      "['std: 0.007678616614487961', 'std: 0.005597705108611525', 'std: 0.0037181661130499546', 'std: 0.0036518991148935284', 'std: 0.0016187131741629084']\n"
     ]
    }
   ],
   "source": [
    "from net18.scenarios2 import get_data_by_scenario_and_case, report_preds_on_validation_files\n",
    "\n",
    "std_results = []\n",
    "for scenario in range(1, 6):\n",
    "    for case in range(1, 4):\n",
    "        print(f'SCENARIO {scenario}, CASE {case} VALIDATION')\n",
    "        s1_c1_data = get_data_by_scenario_and_case(scenario, case)\n",
    "        x = s1_c1_data[0]\n",
    "        x_hat = s1_c1_data[1]\n",
    "        y_all = s1_c1_data[2]\n",
    "        y_hat_all = s1_c1_data[3]\n",
    "        \n",
    "        estim = []\n",
    "        for i in range(num_output):\n",
    "            columns_names = in_columns + [out_columns[i]]\n",
    "            x = in_columns\n",
    "            y = out_columns[i]\n",
    "            \n",
    "            predictor = models[i]\n",
    "            test_x = x_hat\n",
    "            test_y = np.asarray(y_all[0][i]).reshape(-1, 1)\n",
    "            test = pd.DataFrame(np.hstack((test_x, test_y)), columns=columns_names)\n",
    "            \n",
    "            \n",
    "            preds = predictor.predict(test)\n",
    "            \n",
    "            estim.append(preds[0])\n",
    "            \n",
    "        pred = np.asarray(estim)\n",
    "        report_preds_on_validation_files(pred, 8, 'autogloun', scenario, case=case)\n",
    "        if case == 1:\n",
    "            std_results.append(f'std: {np.sqrt(np.mean(np.square(y_all - pred)))}')\n",
    "print(std_results)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T11:53:28.784817800Z",
     "start_time": "2024-02-26T11:51:29.879241200Z"
    }
   },
   "id": "c91c44008cd32294"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std: 0.008439554785042516\n"
     ]
    }
   ],
   "source": [
    "pred = np.asarray(estim)\n",
    "print(f'std: {np.sqrt(np.mean(np.square(y_all - pred)))}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T14:05:34.810183300Z",
     "start_time": "2024-02-23T14:05:34.805170800Z"
    }
   },
   "id": "bf8dba40a9631851"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "621a0939a1bd162f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
